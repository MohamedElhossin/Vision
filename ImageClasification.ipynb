{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClasification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2Q7gDWiFqazlFfMLILL4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedElhossin/Vision/blob/master/ImageClasification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyHiQBsdaDug",
        "colab_type": "text"
      },
      "source": [
        "# **Image classification Note Book**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsrkiySCaRuE",
        "colab_type": "text"
      },
      "source": [
        "### In this note book we will try to make **image classification** on cat/dop dataset using avery simple **Neural Network.**\n",
        "\n",
        "### **Our dataset**\n",
        "As a practical example, we will focus on classifying images as \"dogs\" or \"cats\", in a dataset containing 5000 pictures of cats and dogs (5000 cats, 5000 dogs). We will use 8000 pictures for training and 2000 for testing.\n",
        "\n",
        "**downloading** the data from [Here](https://www.kaggle.com/tongpython/cat-and-dog)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMZqm1s5c0D0",
        "colab_type": "text"
      },
      "source": [
        "## **Mount GDrive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpTsMdp9hz09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "7b33688e-4556-4314-f22b-eed35a7091d5"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "919wRsF2r3CL",
        "colab_type": "text"
      },
      "source": [
        "## **Read the Data from drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KUxE61WsBWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = './path on drive'\n",
        "validation_dir = './path on drive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwE4wfy4i11z",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing and augmentation on data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB7UHtKXjpTp",
        "colab_type": "text"
      },
      "source": [
        "As you already know by now, data should be formatted into appropriately **pre-processed** floating point tensors before being fed into our network. Currently, our data sits on a drive as JPEG files, so the steps for getting it into our network are roughly:\n",
        "\n",
        "* Read the picture files.\n",
        "* Decode the JPEG content to RBG grids of pixels.\n",
        "* Convert these into floating point tensors.\n",
        "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Data augmentation** takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number of random transformations that yield believable-looking images.\n",
        "\n",
        "These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over what we just wrote:\n",
        "\n",
        "* rotation_range is a value in degrees (0-180), a range within which to randomly rotate pictures.\n",
        "* width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
        "* shear_range is for randomly applying shearing transformations.\n",
        "* zoom_range is for randomly zooming inside pictures.\n",
        "* horizontal_flip is for randomly flipping half of the images horizontally\n",
        "* fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shif\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n96n-iN4kqJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNcShyRciNPk",
        "colab_type": "text"
      },
      "source": [
        "## **Building our network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoKv9_qQjACL",
        "colab_type": "text"
      },
      "source": [
        "since we are dealing with bigger images and a more complex problem, we will make our network accordingly larger: it will have one more Conv2D + MaxPooling2D stage. This serves both to augment the capacity of the network, and to further reduce the size of the feature maps, so that they aren't overly large when we reach the Flatten layer. Here, since we start from inputs of size 150x150 (a somewhat arbitrary choice), we end up with feature maps of size 7x7 right before the Flatten layer.\n",
        "\n",
        "we will also add a Dropout layer to our model, right before the densely-connected classifier:\n",
        "\n",
        "**Don't put it with conv layers**\n",
        "\n",
        "Since we are attacking a binary classification problem, we are ending the network with a single unit (a Dense layer of size 1) and a sigmoid activation. This unit will encode the probability that the network is looking at one class or the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLxE7pxeif0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "f1374f92-65e2-4751-c142-703229e8f92f"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "574_9rtFottv",
        "colab_type": "text"
      },
      "source": [
        "## **Train our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xottow5osN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xUqSe3s318l",
        "colab_type": "text"
      },
      "source": [
        "## **Let's plot result of training:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOXenQjXo_nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_abobSMvpDn_",
        "colab_type": "text"
      },
      "source": [
        "## **save our model in the drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX2fnGpNq1gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('gdrive/My Drive/cats_dogs_classification_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}